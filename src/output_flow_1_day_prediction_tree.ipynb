{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a889a08-87ca-4974-ab49-91940bb4e4ad",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LIBRERÍAS GENERALES\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"\")\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from random import seed\n",
    "seed = 123\n",
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "# GRAFICAS\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "# LIBERÍAS PROPIAS EXTERNAS\n",
    "import src.core.utils.graphics as g\n",
    "import src.core.utils.citeec_utils as c\n",
    "import src.core.utils.AI_algorithms as Al\n",
    "import src.core.utils.preprocess.normalize as n\n",
    "import src.core.utils.telebot_api as t\n",
    "# LIBRERÍA PARA HIDROLOGÍA\n",
    "import hydroeval\n",
    "# MULTIPROCESO\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count \n",
    "import concurrent.futures\n",
    "# EJECUCIÓN DE R EN JUPYTER\n",
    "from IPython.display import Audio\n",
    "from IPython import display\n",
    "#%load_ext rpy2.ipython\n",
    "# MODULO PARA MODELAR UN MODELO ARIMA\n",
    "import pmdarima as pm\n",
    "# LIBRERÍAS DE MACHINE LEARNING\n",
    "import torch\n",
    "# KERAS-TENSORFLOW\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense,Reshape,BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras import layers, regularizers, optimizers,losses\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import MeanSquaredError as mse\n",
    "from tensorflow.keras.callbacks import Callback,EarlyStopping\n",
    "# SKLEARN\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import r2_score\n",
    "# XGBOOST\n",
    "from xgboost import XGBRegressor\n",
    "# CONFIGURACIÓN DEL BOT DE TELEGRAM\n",
    "import telebot\n",
    "import io\n",
    "from io import BytesIO\n",
    "import ipynbname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_token = \"6114856166:AAGYqKXk1qSoupZZ9thLQOjT5QevfdL4aMA\"\n",
    "bot = telebot.TeleBot(bot_token, parse_mode=None)\n",
    "idchatconbot = -807792928\n",
    "try:\n",
    "    nombre_archivo = ipynbname.name()\n",
    "except:\n",
    "    nombre_archivo = \"Nombre no disponible\"\n",
    "ultimo_envio = t.enviar_mensaje_con_espera(idchatconbot=idchatconbot, mensaje=f\" ################### INICIO DEL SCRIPT ################### \\n\\n{nombre_archivo}\\n\\nImportado de librerías COMPLETADO\", bot_token=bot_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3efbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_with_parameters(df, normalization_params):\n",
    "    denormalized_df = df.copy()  # Create a copy of the normalized DataFrame\n",
    "    \n",
    "    for column, params in normalization_params.items():\n",
    "        modified_max = params['modified_max']\n",
    "        modified_min = params['modified_min']\n",
    "        \n",
    "        # Denormalize the column using the stored parameters\n",
    "        denormalized_df[column] = (df[column] + modified_min) * (modified_max - modified_min)\n",
    "    \n",
    "    return denormalized_df\n",
    "\n",
    "def denormalize_y_pred(y_pred, qe_params):\n",
    "    modified_max = qe_params['modified_max']\n",
    "    modified_min = qe_params['modified_min']\n",
    "    \n",
    "    # Denormalize the 'Qe' column using the stored parameters\n",
    "    denormalized_y_pred = (y_pred + modified_min) * (modified_max - modified_min)\n",
    "    \n",
    "    return denormalized_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dfdd3e-5c9f-499c-b2ff-65d5d3547ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_dataset = os.path.join('..','..', '..', '..', 'datasets')\n",
    "path_resources = os.path.join('..','..', '..', '..', 'resources','params')\n",
    "\n",
    "df_original = pd.read_csv(os.path.join(path_dataset,'dataframe_original_salida.csv'))\n",
    "df_normalizado = pd.read_csv(os.path.join(path_dataset,'dataframe_normalizado_salida.csv'))\n",
    "\n",
    "with open(os.path.join(path_resources,'normalization_params_salida.json'), 'r') as params_file:\n",
    "    loaded_params = json.load(params_file)\n",
    "    \n",
    "    \n",
    "df_original['Fecha'] = pd.to_datetime(df_original['Fecha'])\n",
    "df_normalizado['Fecha'] = pd.to_datetime(df_normalizado['Fecha'])\n",
    "unique_years = df_original['Fecha'].dt.year.unique()\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af79dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a comprobar si el proceso de normalizado/desnormalizado es correcto\n",
    "# primero desnormalizo el dataset normalizado con los parámetros usados para crearlo\n",
    "denormalized_df = denormalize_with_parameters(df_normalizado, loaded_params)\n",
    "\n",
    "# Como el proceso de normalizado puede dar ligeras variaciones por decimales (punto flotante) fijo una tolerancia aceptable\n",
    "epsilon = 1e-6 \n",
    "\n",
    "# comparo solo las columnas numéricas (no puedo comparar la columna fecha) así que las selecciono\n",
    "numeric_columns = df_original.select_dtypes(include=[np.number]).columns\n",
    "# extraigo las columnas numéricas del dataset original y las paso a numpy para compararlas\n",
    "original_numeric_array = df_original[numeric_columns].to_numpy()\n",
    "# extraigo las columnas numéricas del dataset que acabamos de desnormalizar y las paso a numpy para comparar\n",
    "denormalized_numeric_array = denormalized_df[numeric_columns].to_numpy()\n",
    "\n",
    "# Usando la función de numpy (isclose) comparo ambos arrays, con la tolerancia fijada con epsilon y fuerzo a que todos los valores lo cumplan (np.all) devuelve un booleano:\n",
    "# True si todas lo cumplen, false si alguna no lo cumple\n",
    "are_approx_equal = np.all(np.isclose(original_numeric_array, denormalized_numeric_array, atol=epsilon, equal_nan=True))\n",
    "\n",
    "if are_approx_equal:\n",
    "    print(\"El proceso de normalización/desnormalización funciona correctamente\")\n",
    "else:\n",
    "    print(\"El proceso de normalización/desnormalización no funciona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9677fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voy a hacer una prueba sencilla para asegurarme que la selección de años es correcta:\n",
    "# selecciono los años\n",
    "test_year = 2018\n",
    "val_year = 2019\n",
    "train_years = [year for year in unique_years if year != test_year and year != val_year and year != 2009]\n",
    "print(train_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c66c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraigo los conjuntos de entrenamiento, validación y test del dataframe original y del normalizado usando el año como elemento de selección\n",
    "entrenamiento = df_original[df_original['Fecha'].dt.year.isin(train_years)]\n",
    "validacion = df_original[df_original['Fecha'].dt.year.isin([val_year])]\n",
    "test = df_original[df_original['Fecha'].dt.year.isin([test_year])]\n",
    "\n",
    "entrenamiento_norm = df_normalizado[df_normalizado['Fecha'].dt.year.isin(train_years)]\n",
    "validacion_norm = df_normalizado[df_normalizado['Fecha'].dt.year.isin([val_year])]\n",
    "test_norm = df_normalizado[df_normalizado['Fecha'].dt.year.isin([test_year])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora compruebo los años que contiene cada conjunto y su número de filas y columnas\n",
    "print(entrenamiento['Fecha'].dt.year.unique())\n",
    "print(validacion['Fecha'].dt.year.unique())\n",
    "print(test['Fecha'].dt.year.unique())\n",
    "print(entrenamiento.shape)\n",
    "print(validacion.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo mismo para los conjuntos normalizados\n",
    "print(entrenamiento_norm['Fecha'].dt.year.unique())\n",
    "print(validacion_norm['Fecha'].dt.year.unique())\n",
    "print(test_norm['Fecha'].dt.year.unique())\n",
    "print(entrenamiento_norm.shape)\n",
    "print(validacion_norm.shape)\n",
    "print(test_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27403dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora le quito la columna de fecha para poder entrenar\n",
    "entrenamiento.drop(columns=['Fecha'],inplace=True)\n",
    "validacion.drop(columns=['Fecha'],inplace=True)\n",
    "test.drop(columns=['Fecha'],inplace=True)\n",
    "entrenamiento_norm.drop(columns=['Fecha'],inplace=True)\n",
    "validacion_norm.drop(columns=['Fecha'],inplace=True)\n",
    "test_norm.drop(columns=['Fecha'],inplace=True)\n",
    "\n",
    "# y compruebo que Fecha ha desaparecido\n",
    "test.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474fe7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraigo la columna de la variable a predecir\n",
    "salida = 'Qsalida'\n",
    "\n",
    "y_entrenamiento = entrenamiento[salida]\n",
    "y_validacion = validacion[salida]\n",
    "y_test = test[salida]\n",
    "y_entrenamiento_norm = entrenamiento_norm[salida]\n",
    "y_validacion_norm = validacion_norm[salida]\n",
    "y_test_norm = test_norm[salida]\n",
    "\n",
    "# ahora compruebo que el valor de la salida de la primera fila del conjunto es el del día siguiente para la variable de salida\n",
    "# puesto que el valor Qe de \"hoy\" se usa también como entrada la prueba es facil, se ve como Salida Qe es Original Qe desplazado hacia arriba una posición\n",
    "print(\"Original 'Qsalida':\")\n",
    "print(validacion_norm[salida].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba70827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compruebo que no haya nulos en ningún conjunto\n",
    "print(entrenamiento.isnull().sum().sum(),validacion.isnull().sum().sum(),test.isnull().sum().sum(),y_entrenamiento.isnull().sum(),y_validacion.isnull().sum(),y_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58edc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamaño total 100 ( de 0 a 99)\n",
    "# input width 7\n",
    "# label_width 1\n",
    "# offset 0\n",
    "\n",
    "# i = 90\n",
    "# i + input + offset + label = 90 + 7 + 0 + 1 = 98\n",
    "# coge a x y le mete datos [90:97] 90 91 92 93 94 95 96\n",
    "# coge a y y le mete datos [97:98] 97\n",
    "\n",
    "# i = 92\n",
    "# i + input + offset + label = 92 + 7 + 0 + 1 = 100\n",
    "# coge a x y le mete [i:i+input_width] datos [92:99] 92 93 94 95 96 97 98\n",
    "# coge a y y le mete [i + input_width + offset : i + input_width + offset +label_width] datos [99:100] 99\n",
    "\n",
    "def sliding_window2(data, labels, input_width, label_width=1, offset=1):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "      if i+input_width+ offset + label_width > len (data):\n",
    "        pass\n",
    "      else:\n",
    "        _x = data[i:i+input_width]\n",
    "        _y = labels[i + input_width + offset : i + input_width + offset +label_width]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    x, y = np.array(x),np.array(y)\n",
    "    # quitar esto\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c344ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# añado la ventana temporal en dos tramos, una para lstm (que hace añade una dimensión para cada muestra en la que junta las filas que va a tener en cuenta por muestra)\n",
    "input_width = 7  # días anteriores que le paso de información\n",
    "gap = 0 # predicciones a \"gap\" días vista\n",
    "label_width = 1 # predigo un solo día\n",
    "\n",
    "# sin normalizar\n",
    "x_train, y_train = sliding_window2(entrenamiento, y_entrenamiento, input_width, label_width, gap)\n",
    "x_val, y_val = sliding_window2(validacion, y_validacion, input_width, label_width, gap)\n",
    "x_test, y_tested = sliding_window2(test, y_test, input_width, label_width, gap)\n",
    "# normalizado\n",
    "x_train_norm, y_train_norm = sliding_window2(entrenamiento_norm, y_entrenamiento_norm, input_width, label_width, gap)\n",
    "x_val_norm, y_val_norm = sliding_window2(validacion_norm, y_validacion_norm, input_width, label_width, gap)\n",
    "x_test_norm, y_tested_norm = sliding_window2(test_norm, y_test_norm, input_width, label_width, gap)\n",
    "\n",
    "\n",
    "# y otra para el resto que simplemente replica las columnas con días pasados\n",
    "lista_columnas_retardar = entrenamiento.columns.tolist()\n",
    "print(lista_columnas_retardar)\n",
    "# sin normalizar\n",
    "x_train_modelos = c.añadir_retardo_lista(entrenamiento,entrenamiento,lista_columnas_retardar,input_width)\n",
    "x_val_modelos = c.añadir_retardo_lista(validacion,validacion,lista_columnas_retardar,input_width)\n",
    "x_test_modelos = c.añadir_retardo_lista(test,test,lista_columnas_retardar,input_width)\n",
    "# normalizado\n",
    "x_train_modelos_norm = c.añadir_retardo_lista(entrenamiento_norm,entrenamiento_norm,lista_columnas_retardar,input_width)\n",
    "x_val_modelos_norm = c.añadir_retardo_lista(validacion_norm,validacion_norm,lista_columnas_retardar,input_width)\n",
    "x_test_modelos_norm = c.añadir_retardo_lista(test_norm,test_norm,lista_columnas_retardar,input_width)\n",
    "\n",
    "# le quito el último valor al array de entradas porque el último día solamente se predice, no hacen falta las entradas\n",
    "x_train_modelos = x_train_modelos[:-1]\n",
    "x_val_modelos = x_val_modelos[:-1]\n",
    "x_test_modelos =  x_test_modelos[:-1]\n",
    "# normalizado\n",
    "x_train_modelos_norm = x_train_modelos_norm[:-1]\n",
    "x_val_modelos_norm = x_val_modelos_norm[:-1]\n",
    "x_test_modelos_norm =  x_test_modelos_norm[:-1]\n",
    "\n",
    "\n",
    "num_columns = len(entrenamiento.columns)\n",
    "print(x_train.shape,y_train.shape,x_val.shape,y_val.shape,x_test.shape,y_tested.shape)\n",
    "\n",
    "## ojo, se usa y_tested como valor de predicción, porque al hacer la ventana temporal de lstm usa las primeras filas x filas para predecir la x+1 así que se pierden esas primeras filas\n",
    "## por eso pasa de 364 valores de y originales a 356 (364 - 7 - 1)\n",
    "\n",
    "# lo mismo le ocurre a la parte de modelos, las primeras muestras se pierden en LSTM así que debo eliminarlas en el dataset para el resto de los modelos y así todos los conjuntos trabajan con los mismos datos\n",
    "\n",
    "x_train_modelos = x_train_modelos.iloc[6:,:] #así me elimina las 7 primeras filas que son las que uso de entrada para la primera muestra de lstm\n",
    "x_test_modelos = x_test_modelos.iloc[6:,:]\n",
    "x_train_modelos_norm = x_train_modelos_norm.iloc[6:,:]\n",
    "x_test_modelos_norm = x_test_modelos_norm.iloc[6:,:]\n",
    "print(x_train_modelos.shape,x_test_modelos.shape,x_train_modelos_norm.shape,x_test_modelos_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45adc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compruebo que la ventana en lstm está bien, cada muestra es una matriz que contiene 7 filas de 8 columnas por fila, el primer valor de cada fila es el último valor de Qe conocido que le vamos a dar al modelo\n",
    "print(x_test[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta es la salida de cada una de las matrices mostradas anteriormente\n",
    "print(y_tested[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora voy a comprobar entradas con salidas para el resto de los modelos\n",
    "x_test_modelos[salida].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbbcc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entrenamiento_norm.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.any(np.isnan(x_train_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelobasico(x_train_lstm,y_train_lstm,x_val_lstm,y_val_lstm,batch_size,epochs):\n",
    "    lstm_model =Sequential()\n",
    "    lstm_model.add(LSTM(units = 24))# return_sequences = False \n",
    "    lstm_model.add(Dense(1,activation=tf.keras.activations.linear))\n",
    "    plot_fit = c.PlotLearning(num_capas=1, unidades=24, batch=batch_size, epochs=MAX_EPOCHS)\n",
    "    #history_prueba = entrenar_modelo(lstm_model, x_train_lstm, y_train_lstm, x_val_lstm, y_val_lstm, MAX_EPOCHS, batch_size,num_columns,20,[plot_fit])\n",
    "    #print(f'esto es callback {callbacks}')\n",
    "    lstm_model.compile(loss=tf.losses.MeanAbsoluteError(),\n",
    "                  optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "    history = lstm_model.fit(x_train_lstm,  y_train_lstm, epochs=MAX_EPOCHS,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(x_val_lstm, y_val_lstm),\n",
    "                        callbacks=[plot_fit])#,verbose=False\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44213533",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "MAX_EPOCHS = 500\n",
    "lstm_model = modelobasico( x_train_norm,y_train_norm,x_val_norm,y_val_norm,batch_size,MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_model.predict(x_test_norm)\n",
    "\n",
    "\n",
    "predicciones_LSTM = y_pred.reshape(-1, 1)\n",
    "\n",
    "# desnormalizamos\n",
    "pred_LSTM_denorm = denormalize_y_pred(predicciones_LSTM, loaded_params[salida])\n",
    "y_t = y_tested\n",
    "pred_LSTM_denorm = pred_LSTM_denorm.ravel()\n",
    "pred_LSTM_denorm = pd.DataFrame({salida: pred_LSTM_denorm})\n",
    "\n",
    "# y_datos_test_dn_lstm\n",
    "\n",
    "y_t = np.array(y_t).squeeze(axis=1)\n",
    "print(predicciones_LSTM.shape, y_t.shape)\n",
    "pred_LSTM_denorm = np.array(pred_LSTM_denorm)\n",
    "mse_LSTM = mean_squared_error(y_t, pred_LSTM_denorm)\n",
    "\n",
    "correlacion = np.corrcoef(pred_LSTM_denorm.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LSTM = correlacion ** 2\n",
    "\n",
    "ns_LSTM = hydroeval.nse(y_t.reshape(-1),pred_LSTM_denorm.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_LSTM_denorm.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LSTM = np.std(diff_modelo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6305db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LSTM')\n",
    "print(f'NS test: {ns_LSTM}')\n",
    "print(f'MSE test: {mse_LSTM}')\n",
    "print(f'R2 test: {r_cuadrado_LSTM}')\n",
    "print(f'std test: {std_LSTM}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482291c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_LSTM_denorm , label='LSTM prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372210d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLR = LinearRegression()\n",
    "\n",
    "modeloLR.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247663b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_LR = modeloLR.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_LR = denormalize_y_pred(y_pred_LR, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_LR = mean_squared_error(y_t, pred_denorm_LR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_LR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_LR = hydroeval.nse(y_t.reshape(-1),pred_denorm_LR.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_LR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LR = np.std(diff_modelo_test)\n",
    "print('LR')\n",
    "print(f'NS test: {ns_LR}')\n",
    "print(f'MSE test: {mse_LR}')\n",
    "print(f'R2 test: {r_cuadrado_LR}')\n",
    "print(f'std test: {std_LR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_LR , label='LR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c052d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSVR = SVR()\n",
    "modeloSVR.fit(x_train_modelos_norm,y_train_norm)\n",
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_SVR = modeloSVR.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_SVR = denormalize_y_pred(y_pred_SVR, loaded_params[salida])\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_SVR = mean_squared_error(y_t, pred_denorm_SVR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_SVR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_SVR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_SVR = hydroeval.nse(y_t.reshape(-1),pred_denorm_SVR.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_SVR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_SVR = np.std(diff_modelo_test)\n",
    "print('SVR')\n",
    "print(f'NS test: {ns_SVR}')\n",
    "print(f'MSE test: {mse_SVR}')\n",
    "print(f'R2 test: {r_cuadrado_SVR}')\n",
    "print(f'std test: {std_SVR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e658a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_SVR , label='SVR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloRF = RandomForestRegressor()\n",
    "\n",
    "modeloRF.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_RF = modeloRF.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_RF = denormalize_y_pred(y_pred_RF, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_RF = mean_squared_error(y_t, pred_denorm_RF)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_RF.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_RF = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_RF = hydroeval.nse(y_t.reshape(-1),pred_denorm_RF.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_RF.reshape(-1)-y_t.reshape(-1))     \n",
    "std_RF = np.std(diff_modelo_test)\n",
    "print('RF')\n",
    "print(f'NS test: {ns_RF}')\n",
    "print(f'MSE test: {mse_RF}')\n",
    "print(f'R2 test: {r_cuadrado_RF}')\n",
    "print(f'std test: {std_RF}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_RF , label='RF prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a664450",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloXGB = XGBRegressor()\n",
    "\n",
    "modeloXGB.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df0969",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_XGB = modeloXGB.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_XGB = denormalize_y_pred(y_pred_XGB, loaded_params[salida])\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_XGB = mean_squared_error(y_t, pred_denorm_XGB)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_XGB.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_XGB = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_XGB = hydroeval.nse(y_t.reshape(-1),pred_denorm_XGB.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_XGB.reshape(-1)-y_t.reshape(-1))     \n",
    "std_XGB = np.std(diff_modelo_test)\n",
    "print('XGB')\n",
    "print(f'NS test: {ns_XGB}')\n",
    "print(f'MSE test: {mse_XGB}')\n",
    "print(f'R2 test: {r_cuadrado_XGB}')\n",
    "print(f'std test: {std_XGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_XGB , label='XGB prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(feature_importance_scores, dataset, ultimo_envio):\n",
    "    # Get the feature names from the dataset\n",
    "    feature_names = dataset.columns.values\n",
    "\n",
    "    # Sort the feature importance scores in descending order\n",
    "    sorted_idx = feature_importance_scores.argsort()[::-1]\n",
    "    sorted_scores = feature_importance_scores[sorted_idx]\n",
    "\n",
    "    # Ajustar el tamaño de la gráfica\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    # Aumentar el tamaño de la fuente de los textos\n",
    "    plt.xticks(range(len(sorted_scores)), feature_names[sorted_idx], rotation=270, fontsize=30) # Ajustar el tamaño de la fuente\n",
    "    plt.yticks(fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "\n",
    "    # Reducir el ancho de las barras\n",
    "    plt.bar(range(len(sorted_scores)), sorted_scores, width=0.2)  # Ajustar el ancho de las barras\n",
    "\n",
    "    plt.title(\"Sensitivity Analysis\", fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "    plt.xlabel(\"Variables\", fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "    plt.ylabel(\"RMSE Variation\", fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    presente = time.time()\n",
    "    if presente - ultimo_envio < 3:\n",
    "        time.sleep(3 - (presente-ultimo_envio))\n",
    "    bot.send_photo(idchatconbot, buffer)\n",
    "    ultimo_envio = time.time()\n",
    "    buffer.close()\n",
    "    plt.show()\n",
    "    return ultimo_envio\n",
    "\n",
    "def analisis_sensib_final(modelo,x_data,y_data,norm, salida, ultimo_envio=ultimo_envio):\n",
    "# parte de análisis de sensibilidad con el modelo\n",
    "    # evaluate utiliza la función de pérdida definida en el modelo lstm para calcular el loss entre\n",
    "    # las predicciones y la salida real\n",
    "    if len(x_data.shape) == 3:\n",
    "        num_features = x_data.shape[2]\n",
    "    else:\n",
    "        num_features = x_data.shape[1]\n",
    "    try:\n",
    "        baseline_score = modelo.evaluate(x_data, y_data, verbose=0)[0]\n",
    "        baseline = denormalize_y_pred(baseline_score, loaded_params[salida])\n",
    "        \n",
    "    except AttributeError:\n",
    "        baseline_score = np.mean(cross_val_score(modelo,x_data,y_data,cv=3))\n",
    "        baseline = denormalize_y_pred(baseline_score, loaded_params[salida])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Initialize an array to store the importance scores\n",
    "    feature_importance_scores = np.zeros(num_features)\n",
    "\n",
    "    # Loop through each feature\n",
    "    for i in range(num_features):       \n",
    "        # Evaluate devuelve el loss entre y_pred e y_true\n",
    "        X_removed = x_data.copy()\n",
    "        if len(X_removed.shape) == 3:\n",
    "            X_removed[:,:,i] = 0\n",
    "        else:\n",
    "            X_removed.iloc[:,i] = 0\n",
    "        try:\n",
    "\n",
    "            sc2 = modelo.evaluate(X_removed, y_data, verbose=0)[0]\n",
    "        except AttributeError:\n",
    "\n",
    "            sc2 = np.mean(cross_val_score(modelo,X_removed,y_data,cv=3))\n",
    "        \n",
    "        score = denormalize_y_pred(sc2,loaded_params[salida])\n",
    "\n",
    "        #print(f'loss desnormalizado una variable = 0: {score} loss desnormalizado todas variables: {baseline} , \\nloss normalizado una variable = 0: {sc2} loss normalizado todas variables: {baseline_score} \\n\\n')\n",
    "        # Calculate the decrease in performance\n",
    "        feature_importance_scores[i] = ((score - baseline) / baseline) * 100\n",
    "\n",
    "        # Reset the weights of the model\n",
    "        if len(X_removed.shape) == 3:\n",
    "            modelo.reset_states()\n",
    "    \n",
    "    \n",
    "    mejores_5 = c.rank_five(feature_importance_scores)\n",
    "    nombres = x_train_modelos.columns.tolist()\n",
    "    for j, item in enumerate(mejores_5):\n",
    "        mensaje_rank = f\"Ranking {j+1} feature {nombres[item]} {feature_importance_scores[item]:.3f}%\\n\"\n",
    "        print(mensaje_rank)\n",
    "        #bot.send_message(idchatconbot, mensaje_rank)\n",
    "    #ploteado = g.Graficas(ultimo_envio=ultimo_envio)\n",
    "    ultimo_envio = plot_feature_importance(feature_importance_scores=feature_importance_scores[mejores_5], dataset= x_train_modelos,ultimo_envio=ultimo_envio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838affc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_sensib_final(modeloXGB,x_train_modelos_norm,y_train_norm,loaded_params,salida,ultimo_envio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8156e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a1c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeloANN = Al.crear_red_ann((x_train_modelos_norm,y_train_norm),num_capas_ocultas=1,num_neuronas=24,funcion_activacion=\"sigmoid\",regularizador=0.0001,optimizador=0.001,num_salidas=1,fn_perdida=tf.keras.losses.MeanSquaredError(),metrica=tf.keras.metrics.MeanSquaredError())\n",
    "\n",
    "\n",
    "modeloANN.fit(x_train_modelos_norm,y_train_norm, epochs = MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_ANN = modeloANN.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_ANN = denormalize_y_pred(y_pred_ANN, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_ANN = mean_squared_error(y_t, pred_denorm_ANN)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_ANN.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_ANN = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_ANN = hydroeval.nse(y_t.reshape(-1),pred_denorm_ANN.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_ANN.reshape(-1)-y_t.reshape(-1))     \n",
    "std_ANN = np.std(diff_modelo_test)\n",
    "print('ANN')\n",
    "print(f'NS test: {ns_ANN}')\n",
    "print(f'MSE test: {mse_ANN}')\n",
    "print(f'R2 test: {r_cuadrado_ANN}')\n",
    "print(f'std test: {std_ANN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f739fd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_ANN , label='ANN prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_modelos[salida].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# para naive es simple, cojo el valor de entrada de Qe como predicción\n",
    "\n",
    "y_pred_Naive = x_test_modelos_norm[salida].values\n",
    "# desnormalizamos\n",
    "pred_denorm_Naive = denormalize_y_pred(y_pred_Naive, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_Naive = mean_squared_error(y_t, pred_denorm_Naive)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_Naive.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_Naive = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_Naive = hydroeval.nse(y_t.reshape(-1),pred_denorm_Naive.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_Naive.reshape(-1)-y_t.reshape(-1))     \n",
    "std_Naive = np.std(diff_modelo_test)\n",
    "print('Naive')\n",
    "print(f'NS test: {ns_Naive}')\n",
    "print(f'MSE test: {mse_Naive}')\n",
    "print(f'R2 test: {r_cuadrado_Naive}')\n",
    "print(f'std test: {std_Naive}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c56c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_Naive , label='Naive prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64df42d",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3953b9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "MAX_EPOCHS = 500\n",
    "lstm_model = modelobasico( x_train_norm,y_train_norm,x_val_norm,y_val_norm,batch_size,MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20afde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_model.predict(x_train_norm)\n",
    "\n",
    "\n",
    "predicciones_LSTM = y_pred.reshape(-1, 1)\n",
    "\n",
    "# desnormalizamos\n",
    "pred_LSTM_denorm = denormalize_y_pred(predicciones_LSTM, loaded_params[salida])\n",
    "y_t = y_train\n",
    "pred_LSTM_denorm = pred_LSTM_denorm.ravel()\n",
    "pred_LSTM_denorm = pd.DataFrame({salida: pred_LSTM_denorm})\n",
    "\n",
    "# y_datos_test_dn_lstm\n",
    "\n",
    "y_t = np.array(y_t).squeeze(axis=1)\n",
    "print(predicciones_LSTM.shape, y_t.shape)\n",
    "pred_LSTM_denorm = np.array(pred_LSTM_denorm)\n",
    "mse_LSTM = mean_squared_error(y_t, pred_LSTM_denorm)\n",
    "\n",
    "correlacion = np.corrcoef(pred_LSTM_denorm.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LSTM = correlacion ** 2\n",
    "\n",
    "ns_LSTM = hydroeval.nse(y_t.reshape(-1),pred_LSTM_denorm.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_LSTM_denorm.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LSTM = np.std(diff_modelo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LSTM')\n",
    "print(f'NS train: {ns_LSTM}')\n",
    "print(f'MSE train: {mse_LSTM}')\n",
    "print(f'R2 train: {r_cuadrado_LSTM}')\n",
    "print(f'std train: {std_LSTM}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eacc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_LSTM_denorm , label='LSTM prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bfef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLR = LinearRegression()\n",
    "\n",
    "modeloLR.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_LR = modeloLR.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_LR = denormalize_y_pred(y_pred_LR, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_LR = mean_squared_error(y_t, pred_denorm_LR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_LR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_LR = hydroeval.nse(y_t.reshape(-1),pred_denorm_LR.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_LR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LR = np.std(diff_modelo_train)\n",
    "print('LR')\n",
    "print(f'NS train: {ns_LR}')\n",
    "print(f'MSE train: {mse_LR}')\n",
    "print(f'R2 train: {r_cuadrado_LR}')\n",
    "print(f'std train: {std_LR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7662458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_LR , label='LR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSVR = SVR()\n",
    "modeloSVR.fit(x_train_modelos_norm,y_train_norm)\n",
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_SVR = modeloSVR.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_SVR = denormalize_y_pred(y_pred_SVR, loaded_params[salida])\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_SVR = mean_squared_error(y_t, pred_denorm_SVR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_SVR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_SVR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_SVR = hydroeval.nse(y_t.reshape(-1),pred_denorm_SVR.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_SVR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_SVR = np.std(diff_modelo_train)\n",
    "print('SVR')\n",
    "print(f'NS train: {ns_SVR}')\n",
    "print(f'MSE train: {mse_SVR}')\n",
    "print(f'R2 train: {r_cuadrado_SVR}')\n",
    "print(f'std train: {std_SVR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40843f58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_SVR , label='SVR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloRF = RandomForestRegressor()\n",
    "\n",
    "modeloRF.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_RF = modeloRF.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_RF = denormalize_y_pred(y_pred_RF, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_RF = mean_squared_error(y_t, pred_denorm_RF)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_RF.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_RF = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_RF = hydroeval.nse(y_t.reshape(-1),pred_denorm_RF.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_RF.reshape(-1)-y_t.reshape(-1))     \n",
    "std_RF = np.std(diff_modelo_train)\n",
    "print('RF')\n",
    "print(f'NS train: {ns_RF}')\n",
    "print(f'MSE train: {mse_RF}')\n",
    "print(f'R2 train: {r_cuadrado_RF}')\n",
    "print(f'std train: {std_RF}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_de_caracteristicas = x_train_modelos_norm.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "arbol_seleccionado = modeloRF.estimators_[0]\n",
    "\n",
    "# Crear un archivo DOT que representa la estructura del árbol\n",
    "archivo_dot = export_graphviz(arbol_seleccionado, out_file=None, feature_names=nombre_de_caracteristicas, rounded=True, precision=2)\n",
    "\n",
    "# Visualizar el árbol con Graphviz\n",
    "grafo = graphviz.Source(archivo_dot)\n",
    "grafo.render(\"arbol_visualizado\", format=\"png\", cleanup=True)\n",
    "\n",
    "# Abre el archivo generado para ver el árbol visualizado\n",
    "grafo.view(\"arbol_visualizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eab13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_RF , label='RF prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e905f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloXGB = XGBRegressor()\n",
    "\n",
    "modeloXGB.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51116a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_XGB = modeloXGB.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_XGB = denormalize_y_pred(y_pred_XGB, loaded_params[salida])\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_XGB = mean_squared_error(y_t, pred_denorm_XGB)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_XGB.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_XGB = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_XGB = hydroeval.nse(y_t.reshape(-1),pred_denorm_XGB.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_XGB.reshape(-1)-y_t.reshape(-1))     \n",
    "std_XGB = np.std(diff_modelo_train)\n",
    "print('XGB')\n",
    "print(f'NS train: {ns_XGB}')\n",
    "print(f'MSE train: {mse_XGB}')\n",
    "print(f'R2 train: {r_cuadrado_XGB}')\n",
    "print(f'std train: {std_XGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_XGB , label='XGB prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff6ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeloANN = c.crear_red_ann((x_train_modelos_norm,y_train_norm),num_capas_ocultas=1,num_neuronas=24,funcion_activacion=\"sigmoid\",regularizador=0.0001,optimizador=0.001,num_salidas=1,fn_perdida=tf.keras.losses.MeanSquaredError(),metrica=tf.keras.metrics.MeanSquaredError())\n",
    "\n",
    "\n",
    "modeloANN.fit(x_train_modelos_norm,y_train_norm, epochs = MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_ANN = modeloANN.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_ANN = denormalize_y_pred(y_pred_ANN, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_ANN = mean_squared_error(y_t, pred_denorm_ANN)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_ANN.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_ANN = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_ANN = hydroeval.nse(y_t.reshape(-1),pred_denorm_ANN.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_ANN.reshape(-1)-y_t.reshape(-1))     \n",
    "std_ANN = np.std(diff_modelo_train)\n",
    "print('ANN')\n",
    "print(f'NS train: {ns_ANN}')\n",
    "print(f'MSE train: {mse_ANN}')\n",
    "print(f'R2 train: {r_cuadrado_ANN}')\n",
    "print(f'std train: {std_ANN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc889e6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_ANN , label='ANN prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b103fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_modelos[salida].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# para naive es simple, cojo el valor de entrada de Qe como predicción\n",
    "\n",
    "y_pred_Naive = x_train_modelos_norm[salida].values\n",
    "# desnormalizamos\n",
    "pred_denorm_Naive = denormalize_y_pred(y_pred_Naive, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_Naive = mean_squared_error(y_t, pred_denorm_Naive)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_Naive.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_Naive = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_Naive = hydroeval.nse(y_t.reshape(-1),pred_denorm_Naive.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_Naive.reshape(-1)-y_t.reshape(-1))     \n",
    "std_Naive = np.std(diff_modelo_train)\n",
    "print('Naive')\n",
    "print(f'NS train: {ns_Naive}')\n",
    "print(f'MSE train: {mse_Naive}')\n",
    "print(f'R2 train: {r_cuadrado_Naive}')\n",
    "print(f'std train: {std_Naive}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362c53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_Naive , label='Naive prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
