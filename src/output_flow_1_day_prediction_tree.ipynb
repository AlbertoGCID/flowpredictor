{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a889a08-87ca-4974-ab49-91940bb4e4ad",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 09:59:52.584173: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 09:59:52.584219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 09:59:52.585555: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 09:59:52.593150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 09:59:53.637729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-03 09:59:54.559203: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.599088: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.599349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.600820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.601105: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.601293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.690223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.690460: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.690646: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 09:59:54.690792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2661 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# LIBRERÍAS GENERALES\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"\")\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from typing import Optional\n",
    "from random import seed\n",
    "seed = 123\n",
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "# GRAFICAS\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import seaborn as sns\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "# LIBERÍAS PROPIAS EXTERNAS\n",
    "import src.core.utils.graphics as g\n",
    "import src.core.utils.citeec_utils as c\n",
    "import src.core.utils.AI_algorithms as Al\n",
    "import src.core.utils.preprocess.normalize as n\n",
    "import src.core.utils.telebot_api as t\n",
    "# LIBRERÍA PARA HIDROLOGÍA\n",
    "import hydroeval\n",
    "# MULTIPROCESO\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count \n",
    "import concurrent.futures\n",
    "# EJECUCIÓN DE R EN JUPYTER\n",
    "from IPython.display import Audio\n",
    "from IPython import display\n",
    "#%load_ext rpy2.ipython\n",
    "# MODULO PARA MODELAR UN MODELO ARIMA\n",
    "import pmdarima as pm\n",
    "# LIBRERÍAS DE MACHINE LEARNING\n",
    "import torch\n",
    "# KERAS-TENSORFLOW\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense,Reshape,BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras import layers, regularizers, optimizers,losses\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.metrics import MeanSquaredError as mse\n",
    "from tensorflow.keras.callbacks import Callback,EarlyStopping\n",
    "# SKLEARN\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import r2_score\n",
    "# XGBOOST\n",
    "from xgboost import XGBRegressor\n",
    "# CONFIGURACIÓN DEL BOT DE TELEGRAM\n",
    "import telebot\n",
    "import io\n",
    "from io import BytesIO\n",
    "import ipynbname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RainfallDataset:\n",
    "    def __init__(self, data_path, columns=None, normalization_params=None, temporal_windows=None):\n",
    "        self.data_path = data_path\n",
    "        self.columns = columns\n",
    "        self.normalization_params = normalization_params\n",
    "        self.temporal_windows = temporal_windows\n",
    "        self.data: pd.DataFrame = None\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.model = None\n",
    "\n",
    "    def load_data(self, data_path, temporal_column):\n",
    "            # Cargar datos desde el archivo especificado y añadir al DataFrame existente\n",
    "            new_data = pd.read_csv(data_path)\n",
    "            new_data = new_data.rename(columns={temporal_column: 'date'})\n",
    "            new_data['date'] = pd.to_datetime(new_data['date'], errors='coerce')\n",
    "            if self.data is None:\n",
    "                self.data = new_data\n",
    "            else:\n",
    "                self.data = pd.merge(self.data, new_data, how='outer', on='date')\n",
    "            \n",
    "\n",
    "    def normalize_data(self):\n",
    "        if self.normalization_params:\n",
    "            # Normalizar datos según los parámetros proporcionados\n",
    "            scaler = StandardScaler(**self.normalization_params)\n",
    "            self.data[self.columns] = scaler.fit_transform(self.data[self.columns])\n",
    "\n",
    "    def create_temporal_windows(self):\n",
    "        if self.temporal_windows:\n",
    "            pass\n",
    "            # Crear ventanas temporales según los índices proporcionados\n",
    "            # ...\n",
    "\n",
    "    def extract_features(self, extraction_mode='default'):\n",
    "        if extraction_mode == 'default':\n",
    "            print(\"hola\")\n",
    "            # Extraer características de datos de acuerdo al modo predeterminado\n",
    "            # ...\n",
    "        elif extraction_mode == 'custom':\n",
    "            pass\n",
    "            # Modo de extracción personalizado\n",
    "            # ...\n",
    "\n",
    "    def split_data(self, test_size=0.2):\n",
    "        # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.data[self.columns], self.data['target_column'], test_size=test_size, random_state=42\n",
    "        )\n",
    "\n",
    "    def train_model(self):\n",
    "        # Entrenar un modelo RandomForestRegressor\n",
    "        self.model = RandomForestRegressor()\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "\n",
    "    def fine_tune_model(self, params):\n",
    "        pass\n",
    "        # Ajustar hiperparámetros del modelo\n",
    "        # ...\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        # Realizar predicciones con el modelo entrenado\n",
    "        return self.model.predict(input_data)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        # Evaluar el modelo en el conjunto de prueba\n",
    "        predictions = self.model.predict(self.X_test)\n",
    "        mse = mean_squared_error(self.y_test, predictions)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_token = \"6114856166:AAGYqKXk1qSoupZZ9thLQOjT5QevfdL4aMA\"\n",
    "bot = telebot.TeleBot(bot_token, parse_mode=None)\n",
    "idchatconbot = -807792928\n",
    "try:\n",
    "    nombre_archivo = ipynbname.name()\n",
    "except:\n",
    "    nombre_archivo = \"Nombre no disponible\"\n",
    "ultimo_envio = t.enviar_mensaje_con_espera(idchatconbot=idchatconbot, mensaje=f\" ################### INICIO DEL SCRIPT ################### \\n\\n{nombre_archivo}\\n\\nImportado de librerías COMPLETADO\", bot_token=bot_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3efbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_with_parameters(df, normalization_params):\n",
    "    denormalized_df = df.copy()  # Create a copy of the normalized DataFrame\n",
    "    \n",
    "    for column, params in normalization_params.items():\n",
    "        modified_max = params['modified_max']\n",
    "        modified_min = params['modified_min']\n",
    "        \n",
    "        # Denormalize the column using the stored parameters\n",
    "        denormalized_df[column] = (df[column] + modified_min) * (modified_max - modified_min)\n",
    "    \n",
    "    return denormalized_df\n",
    "\n",
    "def denormalize_y_pred(y_pred, qe_params):\n",
    "    modified_max = qe_params['modified_max']\n",
    "    modified_min = qe_params['modified_min']\n",
    "    \n",
    "    # Denormalize the 'Qe' column using the stored parameters\n",
    "    denormalized_y_pred = (y_pred + modified_min) * (modified_max - modified_min)\n",
    "    \n",
    "    return denormalized_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33dfdd3e-5c9f-499c-b2ff-65d5d3547ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Qe</th>\n",
       "      <th>l/m2_arzua</th>\n",
       "      <th>l/m2_olveda</th>\n",
       "      <th>l/m2_serradofaro</th>\n",
       "      <th>l/m2_melide</th>\n",
       "      <th>Qsalida</th>\n",
       "      <th>pred_l/m2_2d</th>\n",
       "      <th>pred_l/m2_3d</th>\n",
       "      <th>pred_l/m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>133.68</td>\n",
       "      <td>5.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>116.57</td>\n",
       "      <td>14.370668</td>\n",
       "      <td>8.574286</td>\n",
       "      <td>11.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>187.69</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>17.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>116.22</td>\n",
       "      <td>3.231000</td>\n",
       "      <td>7.022286</td>\n",
       "      <td>12711.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>115.16</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>117.35</td>\n",
       "      <td>10.009143</td>\n",
       "      <td>0.024286</td>\n",
       "      <td>8.633714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>145.71</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>117.18</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.240143</td>\n",
       "      <td>13.482714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>101.82</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>117.21</td>\n",
       "      <td>0.279143</td>\n",
       "      <td>2.343286</td>\n",
       "      <td>0.010714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fecha      Qe  l/m2_arzua  l/m2_olveda  l/m2_serradofaro  l/m2_melide  \\\n",
       "0 2009-12-31  133.68         5.8         23.0               5.3         11.4   \n",
       "1 2010-01-01  187.69         9.8         23.6              17.9         11.4   \n",
       "2 2010-01-02  115.16         3.6          2.8               6.6          2.2   \n",
       "3 2010-01-03  145.71        15.0         10.0              26.9         10.8   \n",
       "4 2010-01-04  101.82         0.2          0.2               0.0          0.2   \n",
       "\n",
       "   Qsalida  pred_l/m2_2d  pred_l/m2_3d     pred_l/m2  \n",
       "0   116.57     14.370668      8.574286     11.030000  \n",
       "1   116.22      3.231000      7.022286  12711.000000  \n",
       "2   117.35     10.009143      0.024286      8.633714  \n",
       "3   117.18      0.000571      0.240143     13.482714  \n",
       "4   117.21      0.279143      2.343286      0.010714  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# primero hay que elegir la ruta donde están los datasets\n",
    "path_dataset = os.path.join( '..', 'datasets')\n",
    "\n",
    "# y la ruta de los recursos\n",
    "path_resources = os.path.join( '..', 'resources','params')\n",
    "\n",
    "df_original = pd.read_csv(os.path.join(path_dataset,'dataframe_original_salida.csv'))\n",
    "df_normalizado = pd.read_csv(os.path.join(path_dataset,'dataframe_normalizado_salida.csv'))\n",
    "\n",
    "with open(os.path.join(path_resources,'normalization_params_salida.json'), 'r') as params_file:\n",
    "    loaded_params = json.load(params_file)\n",
    "    \n",
    "    \n",
    "df_original['Fecha'] = pd.to_datetime(df_original['Fecha'])\n",
    "df_normalizado['Fecha'] = pd.to_datetime(df_normalizado['Fecha'])\n",
    "unique_years = df_original['Fecha'].dt.year.unique()\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af79dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El proceso de normalización/desnormalización funciona correctamente\n"
     ]
    }
   ],
   "source": [
    "# Voy a comprobar si el proceso de normalizado/desnormalizado es correcto\n",
    "# primero desnormalizo el dataset normalizado con los parámetros usados para crearlo\n",
    "denormalized_df = denormalize_with_parameters(df_normalizado, loaded_params)\n",
    "\n",
    "# Como el proceso de normalizado puede dar ligeras variaciones por decimales (punto flotante) fijo una tolerancia aceptable\n",
    "epsilon = 1e-6 \n",
    "\n",
    "# comparo solo las columnas numéricas (no puedo comparar la columna fecha) así que las selecciono\n",
    "numeric_columns = df_original.select_dtypes(include=[np.number]).columns\n",
    "# extraigo las columnas numéricas del dataset original y las paso a numpy para compararlas\n",
    "original_numeric_array = df_original[numeric_columns].to_numpy()\n",
    "# extraigo las columnas numéricas del dataset que acabamos de desnormalizar y las paso a numpy para comparar\n",
    "denormalized_numeric_array = denormalized_df[numeric_columns].to_numpy()\n",
    "\n",
    "# Usando la función de numpy (isclose) comparo ambos arrays, con la tolerancia fijada con epsilon y fuerzo a que todos los valores lo cumplan (np.all) devuelve un booleano:\n",
    "# True si todas lo cumplen, false si alguna no lo cumple\n",
    "are_approx_equal = np.all(np.isclose(original_numeric_array, denormalized_numeric_array, atol=epsilon, equal_nan=True))\n",
    "\n",
    "if are_approx_equal:\n",
    "    print(\"El proceso de normalización/desnormalización funciona correctamente\")\n",
    "else:\n",
    "    print(\"El proceso de normalización/desnormalización no funciona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9677fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2020, 2021, 2022]\n"
     ]
    }
   ],
   "source": [
    "# voy a hacer una prueba sencilla para asegurarme que la selección de años es correcta:\n",
    "# selecciono los años\n",
    "test_year = 2018\n",
    "val_year = 2019\n",
    "train_years = [year for year in unique_years if year != test_year and year != val_year and year != 2009]\n",
    "print(train_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c66c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraigo los conjuntos de entrenamiento, validación y test del dataframe original y del normalizado usando el año como elemento de selección\n",
    "entrenamiento = df_original[df_original['Fecha'].dt.year.isin(train_years)]\n",
    "validacion = df_original[df_original['Fecha'].dt.year.isin([val_year])]\n",
    "test = df_original[df_original['Fecha'].dt.year.isin([test_year])]\n",
    "\n",
    "entrenamiento_norm = df_normalizado[df_normalizado['Fecha'].dt.year.isin(train_years)]\n",
    "validacion_norm = df_normalizado[df_normalizado['Fecha'].dt.year.isin([val_year])]\n",
    "test_norm = df_normalizado[df_normalizado['Fecha'].dt.year.isin([test_year])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559d3bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010 2011 2012 2013 2014 2015 2016 2017 2020 2021 2022]\n",
      "[2019]\n",
      "[2018]\n",
      "(3822, 10)\n",
      "(364, 10)\n",
      "(364, 10)\n"
     ]
    }
   ],
   "source": [
    "# ahora compruebo los años que contiene cada conjunto y su número de filas y columnas\n",
    "print(entrenamiento['Fecha'].dt.year.unique())\n",
    "print(validacion['Fecha'].dt.year.unique())\n",
    "print(test['Fecha'].dt.year.unique())\n",
    "print(entrenamiento.shape)\n",
    "print(validacion.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c397a95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2010 2011 2012 2013 2014 2015 2016 2017 2020 2021 2022]\n",
      "[2019]\n",
      "[2018]\n",
      "(3822, 10)\n",
      "(364, 10)\n",
      "(364, 10)\n"
     ]
    }
   ],
   "source": [
    "# lo mismo para los conjuntos normalizados\n",
    "print(entrenamiento_norm['Fecha'].dt.year.unique())\n",
    "print(validacion_norm['Fecha'].dt.year.unique())\n",
    "print(test_norm['Fecha'].dt.year.unique())\n",
    "print(entrenamiento_norm.shape)\n",
    "print(validacion_norm.shape)\n",
    "print(test_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27403dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21804/3655676230.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entrenamiento.drop(columns=['Fecha'],inplace=True)\n",
      "/tmp/ipykernel_21804/3655676230.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validacion.drop(columns=['Fecha'],inplace=True)\n",
      "/tmp/ipykernel_21804/3655676230.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.drop(columns=['Fecha'],inplace=True)\n",
      "/tmp/ipykernel_21804/3655676230.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entrenamiento_norm.drop(columns=['Fecha'],inplace=True)\n",
      "/tmp/ipykernel_21804/3655676230.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validacion_norm.drop(columns=['Fecha'],inplace=True)\n",
      "/tmp/ipykernel_21804/3655676230.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_norm.drop(columns=['Fecha'],inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qe</th>\n",
       "      <th>l/m2_arzua</th>\n",
       "      <th>l/m2_olveda</th>\n",
       "      <th>l/m2_serradofaro</th>\n",
       "      <th>l/m2_melide</th>\n",
       "      <th>Qsalida</th>\n",
       "      <th>pred_l/m2_2d</th>\n",
       "      <th>pred_l/m2_3d</th>\n",
       "      <th>pred_l/m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>45.855704</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.570286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>41.370850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.66</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>37.083484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>33.886712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.003000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>30.607756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.77</td>\n",
       "      <td>3.223857</td>\n",
       "      <td>0.617143</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>30.493781</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.713571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.718857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>28.326371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.68</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>27.212682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>24.894556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>23.756132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.64</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Qe  l/m2_arzua  l/m2_olveda  l/m2_serradofaro  l/m2_melide  \\\n",
       "3130  45.855704         2.2          0.0               2.2          0.4   \n",
       "3131  41.370850         0.0          0.0               0.0          0.0   \n",
       "3132  37.083484         0.0          0.0               0.0          0.0   \n",
       "3133  33.886712         0.0          0.0               0.0          0.0   \n",
       "3134  30.607756         0.0          0.0               0.0          0.0   \n",
       "3135  30.493781         2.0          2.7               2.6          3.8   \n",
       "3136  28.326371         0.0          0.0               0.0          0.0   \n",
       "3137  27.212682         0.0          0.0               0.0          0.0   \n",
       "3138  24.894556         0.0          0.0               0.0          0.0   \n",
       "3139  23.756132         0.0          0.0               0.0          0.0   \n",
       "\n",
       "      Qsalida  pred_l/m2_2d  pred_l/m2_3d  pred_l/m2  \n",
       "3130    22.41      0.000000      0.000000   1.570286  \n",
       "3131    16.66      0.000000      0.000000   0.000000  \n",
       "3132    15.60      0.000000      0.000071   0.000000  \n",
       "3133    15.70      0.000000      3.003000   0.000000  \n",
       "3134    15.77      3.223857      0.617143   0.000000  \n",
       "3135    15.60      0.713571      0.000000   2.718857  \n",
       "3136    15.68      0.000471      0.000000   0.035914  \n",
       "3137    15.68      0.000000      0.000000   0.000000  \n",
       "3138    15.64      0.000000      0.000000   0.000000  \n",
       "3139    15.64      0.000000      0.000043   0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ahora le quito la columna de fecha para poder entrenar\n",
    "entrenamiento.drop(columns=['Fecha'],inplace=True)\n",
    "validacion.drop(columns=['Fecha'],inplace=True)\n",
    "test.drop(columns=['Fecha'],inplace=True)\n",
    "entrenamiento_norm.drop(columns=['Fecha'],inplace=True)\n",
    "validacion_norm.drop(columns=['Fecha'],inplace=True)\n",
    "test_norm.drop(columns=['Fecha'],inplace=True)\n",
    "\n",
    "# y compruebo que Fecha ha desaparecido\n",
    "test.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "474fe7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 'Qsalida':\n",
      "3140    0.055362\n",
      "3141    0.055327\n",
      "3142    0.055221\n",
      "3143    0.090786\n",
      "3144    0.055716\n",
      "Name: Qsalida, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extraigo la columna de la variable a predecir\n",
    "salida = 'Qsalida'\n",
    "\n",
    "y_entrenamiento = entrenamiento[salida]\n",
    "y_validacion = validacion[salida]\n",
    "y_test = test[salida]\n",
    "y_entrenamiento_norm = entrenamiento_norm[salida]\n",
    "y_validacion_norm = validacion_norm[salida]\n",
    "y_test_norm = test_norm[salida]\n",
    "\n",
    "# ahora compruebo que el valor de la salida de la primera fila del conjunto es el del día siguiente para la variable de salida\n",
    "# puesto que el valor Qe de \"hoy\" se usa también como entrada la prueba es facil, se ve como Salida Qe es Original Qe desplazado hacia arriba una posición\n",
    "print(\"Original 'Qsalida':\")\n",
    "print(validacion_norm[salida].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba70827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "# compruebo que no haya nulos en ningún conjunto\n",
    "print(entrenamiento.isnull().sum().sum(),validacion.isnull().sum().sum(),test.isnull().sum().sum(),y_entrenamiento.isnull().sum(),y_validacion.isnull().sum(),y_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c58edc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamaño total 100 ( de 0 a 99)\n",
    "# input width 7\n",
    "# label_width 1\n",
    "# offset 0\n",
    "\n",
    "# i = 90\n",
    "# i + input + offset + label = 90 + 7 + 0 + 1 = 98\n",
    "# coge a x y le mete datos [90:97] 90 91 92 93 94 95 96\n",
    "# coge a y y le mete datos [97:98] 97\n",
    "\n",
    "# i = 92\n",
    "# i + input + offset + label = 92 + 7 + 0 + 1 = 100\n",
    "# coge a x y le mete [i:i+input_width] datos [92:99] 92 93 94 95 96 97 98\n",
    "# coge a y y le mete [i + input_width + offset : i + input_width + offset +label_width] datos [99:100] 99\n",
    "\n",
    "def sliding_window2(data, labels, input_width, label_width=1, offset=1):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "      if i+input_width+ offset + label_width > len (data):\n",
    "        pass\n",
    "      else:\n",
    "        _x = data[i:i+input_width]\n",
    "        _y = labels[i + input_width + offset : i + input_width + offset +label_width]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "\n",
    "    x, y = np.array(x),np.array(y)\n",
    "    # quitar esto\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c344ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Qe', 'l/m2_arzua', 'l/m2_olveda', 'l/m2_serradofaro', 'l/m2_melide', 'Qsalida', 'pred_l/m2_2d', 'pred_l/m2_3d', 'pred_l/m2']\n",
      "(3815, 7, 9) (3815, 1) (357, 7, 9) (357, 1) (357, 7, 9) (357, 1)\n",
      "(3815, 63) (357, 63) (3815, 63) (357, 63)\n"
     ]
    }
   ],
   "source": [
    "# añado la ventana temporal en dos tramos, una para lstm (que hace añade una dimensión para cada muestra en la que junta las filas que va a tener en cuenta por muestra)\n",
    "input_width = 7  # días anteriores que le paso de información\n",
    "gap = 0 # predicciones a \"gap\" días vista\n",
    "label_width = 1 # predigo un solo día\n",
    "\n",
    "# sin normalizar\n",
    "x_train, y_train = sliding_window2(entrenamiento, y_entrenamiento, input_width, label_width, gap)\n",
    "x_val, y_val = sliding_window2(validacion, y_validacion, input_width, label_width, gap)\n",
    "x_test, y_tested = sliding_window2(test, y_test, input_width, label_width, gap)\n",
    "# normalizado\n",
    "x_train_norm, y_train_norm = sliding_window2(entrenamiento_norm, y_entrenamiento_norm, input_width, label_width, gap)\n",
    "x_val_norm, y_val_norm = sliding_window2(validacion_norm, y_validacion_norm, input_width, label_width, gap)\n",
    "x_test_norm, y_tested_norm = sliding_window2(test_norm, y_test_norm, input_width, label_width, gap)\n",
    "\n",
    "\n",
    "# y otra para el resto que simplemente replica las columnas con días pasados\n",
    "lista_columnas_retardar = entrenamiento.columns.tolist()\n",
    "print(lista_columnas_retardar)\n",
    "# sin normalizar\n",
    "x_train_modelos = c.añadir_retardo_lista(entrenamiento,entrenamiento,lista_columnas_retardar,input_width)\n",
    "x_val_modelos = c.añadir_retardo_lista(validacion,validacion,lista_columnas_retardar,input_width)\n",
    "x_test_modelos = c.añadir_retardo_lista(test,test,lista_columnas_retardar,input_width)\n",
    "# normalizado\n",
    "x_train_modelos_norm = c.añadir_retardo_lista(entrenamiento_norm,entrenamiento_norm,lista_columnas_retardar,input_width)\n",
    "x_val_modelos_norm = c.añadir_retardo_lista(validacion_norm,validacion_norm,lista_columnas_retardar,input_width)\n",
    "x_test_modelos_norm = c.añadir_retardo_lista(test_norm,test_norm,lista_columnas_retardar,input_width)\n",
    "\n",
    "# le quito el último valor al array de entradas porque el último día solamente se predice, no hacen falta las entradas\n",
    "x_train_modelos = x_train_modelos[:-1]\n",
    "x_val_modelos = x_val_modelos[:-1]\n",
    "x_test_modelos =  x_test_modelos[:-1]\n",
    "# normalizado\n",
    "x_train_modelos_norm = x_train_modelos_norm[:-1]\n",
    "x_val_modelos_norm = x_val_modelos_norm[:-1]\n",
    "x_test_modelos_norm =  x_test_modelos_norm[:-1]\n",
    "\n",
    "\n",
    "num_columns = len(entrenamiento.columns)\n",
    "print(x_train.shape,y_train.shape,x_val.shape,y_val.shape,x_test.shape,y_tested.shape)\n",
    "\n",
    "## ojo, se usa y_tested como valor de predicción, porque al hacer la ventana temporal de lstm usa las primeras filas x filas para predecir la x+1 así que se pierden esas primeras filas\n",
    "## por eso pasa de 364 valores de y originales a 356 (364 - 7 - 1)\n",
    "\n",
    "# lo mismo le ocurre a la parte de modelos, las primeras muestras se pierden en LSTM así que debo eliminarlas en el dataset para el resto de los modelos y así todos los conjuntos trabajan con los mismos datos\n",
    "\n",
    "x_train_modelos = x_train_modelos.iloc[6:,:] #así me elimina las 7 primeras filas que son las que uso de entrada para la primera muestra de lstm\n",
    "x_test_modelos = x_test_modelos.iloc[6:,:]\n",
    "x_train_modelos_norm = x_train_modelos_norm.iloc[6:,:]\n",
    "x_test_modelos_norm = x_test_modelos_norm.iloc[6:,:]\n",
    "print(x_train_modelos.shape,x_test_modelos.shape,x_train_modelos_norm.shape,x_test_modelos_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b45adc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4.58557039e+01 2.20000000e+00 0.00000000e+00 2.20000000e+00\n",
      "   4.00000000e-01 2.24100000e+01 0.00000000e+00 0.00000000e+00\n",
      "   1.57028570e+00]\n",
      "  [4.13708498e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.66600000e+01 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00]\n",
      "  [3.70834844e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56000000e+01 0.00000000e+00 7.14285750e-05\n",
      "   0.00000000e+00]\n",
      "  [3.38867122e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.57000000e+01 0.00000000e+00 3.00300000e+00\n",
      "   0.00000000e+00]\n",
      "  [3.06077561e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.57700000e+01 3.22385720e+00 6.17142830e-01\n",
      "   0.00000000e+00]\n",
      "  [3.04937810e+01 2.00000000e+00 2.70000000e+00 2.60000000e+00\n",
      "   3.80000000e+00 1.56000000e+01 7.13571420e-01 0.00000000e+00\n",
      "   2.71885710e+00]\n",
      "  [2.83263714e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56800000e+01 4.71428540e-04 0.00000000e+00\n",
      "   3.59142860e-02]]\n",
      "\n",
      " [[4.13708498e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.66600000e+01 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00]\n",
      "  [3.70834844e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56000000e+01 0.00000000e+00 7.14285750e-05\n",
      "   0.00000000e+00]\n",
      "  [3.38867122e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.57000000e+01 0.00000000e+00 3.00300000e+00\n",
      "   0.00000000e+00]\n",
      "  [3.06077561e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.57700000e+01 3.22385720e+00 6.17142830e-01\n",
      "   0.00000000e+00]\n",
      "  [3.04937810e+01 2.00000000e+00 2.70000000e+00 2.60000000e+00\n",
      "   3.80000000e+00 1.56000000e+01 7.13571420e-01 0.00000000e+00\n",
      "   2.71885710e+00]\n",
      "  [2.83263714e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56800000e+01 4.71428540e-04 0.00000000e+00\n",
      "   3.59142860e-02]\n",
      "  [2.72126816e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56800000e+01 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00]]\n",
      "\n",
      " [[3.70834844e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56000000e+01 0.00000000e+00 7.14285750e-05\n",
      "   0.00000000e+00]\n",
      "  [3.38867122e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.57000000e+01 0.00000000e+00 3.00300000e+00\n",
      "   0.00000000e+00]\n",
      "  [3.06077561e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.57700000e+01 3.22385720e+00 6.17142830e-01\n",
      "   0.00000000e+00]\n",
      "  [3.04937810e+01 2.00000000e+00 2.70000000e+00 2.60000000e+00\n",
      "   3.80000000e+00 1.56000000e+01 7.13571420e-01 0.00000000e+00\n",
      "   2.71885710e+00]\n",
      "  [2.83263714e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56800000e+01 4.71428540e-04 0.00000000e+00\n",
      "   3.59142860e-02]\n",
      "  [2.72126816e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56800000e+01 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00]\n",
      "  [2.48945562e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 1.56400000e+01 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# compruebo que la ventana en lstm está bien, cada muestra es una matriz que contiene 7 filas de 8 columnas por fila, el primer valor de cada fila es el último valor de Qe conocido que le vamos a dar al modelo\n",
    "print(x_test[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fbd2158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.68]\n",
      " [15.64]\n",
      " [15.64]]\n"
     ]
    }
   ],
   "source": [
    "# esta es la salida de cada una de las matrices mostradas anteriormente\n",
    "print(y_tested[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af4f407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3129    17.72\n",
       "3130    22.41\n",
       "3131    16.66\n",
       "3132    15.60\n",
       "3133    15.70\n",
       "3134    15.77\n",
       "3135    15.60\n",
       "3136    15.68\n",
       "3137    15.68\n",
       "3138    15.64\n",
       "Name: Qsalida, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ahora voy a comprobar entradas con salidas para el resto de los modelos\n",
    "x_test_modelos[salida].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfbbcc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qe                  0\n",
      "l/m2_arzua          0\n",
      "l/m2_olveda         0\n",
      "l/m2_serradofaro    0\n",
      "l/m2_melide         0\n",
      "Qsalida             0\n",
      "pred_l/m2_2d        0\n",
      "pred_l/m2_3d        0\n",
      "pred_l/m2           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(entrenamiento_norm.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "217b0fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.any(np.isnan(x_train_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0079ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelobasico(x_train_lstm,y_train_lstm,x_val_lstm,y_val_lstm,batch_size,epochs):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(units = 24))# return_sequences = False \n",
    "    lstm_model.add(Dense(1,activation=tf.keras.activations.linear))\n",
    "    plot_fit = c.PlotLearning(num_capas=1, unidades=24, batch=batch_size, epochs=MAX_EPOCHS)\n",
    "    #history_prueba = entrenar_modelo(lstm_model, x_train_lstm, y_train_lstm, x_val_lstm, y_val_lstm, MAX_EPOCHS, batch_size,num_columns,20,[plot_fit])\n",
    "    #print(f'esto es callback {callbacks}')\n",
    "    lstm_model.compile(loss=tf.losses.MeanAbsoluteError(),\n",
    "                  optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "    history = lstm_model.fit(x_train_lstm,  y_train_lstm, epochs=MAX_EPOCHS,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=(x_val_lstm, y_val_lstm),\n",
    "                        callbacks=[plot_fit])#,verbose=False\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3815, 7, 9) (3815, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "[[[3.86929059e-01 7.08912037e-02 1.87123375e-01 9.00764895e-02\n",
      "   8.96226415e-02 4.10868827e-01 2.60634190e-02 4.93169314e-02\n",
      "   3.33359559e-01]\n",
      "  [2.37406097e-01 2.60416667e-02 2.22010783e-02 3.32125604e-02\n",
      "   1.72955975e-02 4.14863680e-01 8.07404789e-02 1.70557117e-04\n",
      "   2.26428384e-04]\n",
      "  [3.00385919e-01 1.08506944e-01 7.92895655e-02 1.35366345e-01\n",
      "   8.49056604e-02 4.14262685e-01 4.60963266e-06 1.68650318e-03\n",
      "   3.53598584e-04]\n",
      "  [2.09905252e-01 1.44675926e-03 1.58579131e-03 0.00000000e+00\n",
      "   1.57232704e-03 4.14368743e-01 2.25175404e-03 1.64567018e-02\n",
      "   2.80993601e-07]\n",
      "  [1.72261666e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 4.15111149e-01 5.18214571e-02 2.40053344e-02\n",
      "   6.33921558e-06]\n",
      "  [1.47894351e-01 7.23379630e-03 0.00000000e+00 3.52254428e-03\n",
      "   0.00000000e+00 3.07320833e-01 5.34117443e-02 5.15251382e-02\n",
      "   1.40062192e-04]\n",
      "  [1.35731308e-01 2.74884259e-02 0.00000000e+00 2.51610306e-03\n",
      "   3.14465409e-03 3.09053114e-01 1.90788325e-02 1.45374382e-03\n",
      "   1.54213029e-04]]\n",
      "\n",
      " [[2.37406097e-01 2.60416667e-02 2.22010783e-02 3.32125604e-02\n",
      "   1.72955975e-02 4.14863680e-01 8.07404789e-02 1.70557117e-04\n",
      "   2.26428384e-04]\n",
      "  [3.00385919e-01 1.08506944e-01 7.92895655e-02 1.35366345e-01\n",
      "   8.49056604e-02 4.14262685e-01 4.60963266e-06 1.68650318e-03\n",
      "   3.53598584e-04]\n",
      "  [2.09905252e-01 1.44675926e-03 1.58579131e-03 0.00000000e+00\n",
      "   1.57232704e-03 4.14368743e-01 2.25175404e-03 1.64567018e-02\n",
      "   2.80993601e-07]\n",
      "  [1.72261666e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 4.15111149e-01 5.18214571e-02 2.40053344e-02\n",
      "   6.33921558e-06]\n",
      "  [1.47894351e-01 7.23379630e-03 0.00000000e+00 3.52254428e-03\n",
      "   0.00000000e+00 3.07320833e-01 5.34117443e-02 5.15251382e-02\n",
      "   1.40062192e-04]\n",
      "  [1.35731308e-01 2.74884259e-02 0.00000000e+00 2.51610306e-03\n",
      "   3.14465409e-03 3.09053114e-01 1.90788325e-02 1.45374382e-03\n",
      "   1.54213029e-04]\n",
      "  [1.22042731e-01 5.06365741e-03 0.00000000e+00 7.04508857e-03\n",
      "   1.57232704e-03 3.11527801e-01 5.34013722e-03 2.72790160e-03\n",
      "   6.19684527e-05]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_norm.shape,y_train_norm.shape)\n",
    "print(type(x_train_norm))\n",
    "print(x_train_norm[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44213533",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "114/120 [===========================>..] - ETA: 0s - loss: 0.0222 - mean_absolute_error: 0.0222"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 3s 8ms/step - loss: 0.0220 - mean_absolute_error: 0.0220 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/10\n",
      "117/120 [============================>.] - ETA: 0s - loss: 0.0159 - mean_absolute_error: 0.0159"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0159 - mean_absolute_error: 0.0159 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 3/10\n",
      "116/120 [============================>.] - ETA: 0s - loss: 0.0150 - mean_absolute_error: 0.0150"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0150 - mean_absolute_error: 0.0150 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
      "Epoch 4/10\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.0142 - mean_absolute_error: 0.0142"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "Epoch 5/10\n",
      "118/120 [============================>.] - ETA: 0s - loss: 0.0139 - mean_absolute_error: 0.0139"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0140 - mean_absolute_error: 0.0140 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 6/10\n",
      "108/120 [==========================>...] - ETA: 0s - loss: 0.0147 - mean_absolute_error: 0.0147"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 7ms/step - loss: 0.0148 - mean_absolute_error: 0.0148 - val_loss: 0.0192 - val_mean_absolute_error: 0.0192\n",
      "Epoch 7/10\n",
      "111/120 [==========================>...] - ETA: 0s - loss: 0.0144 - mean_absolute_error: 0.0144"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0192 - val_mean_absolute_error: 0.0192\n",
      "Epoch 8/10\n",
      "110/120 [==========================>...] - ETA: 0s - loss: 0.0142 - mean_absolute_error: 0.0142"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0142 - mean_absolute_error: 0.0142 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
      "Epoch 9/10\n",
      "109/120 [==========================>...] - ETA: 0s - loss: 0.0137 - mean_absolute_error: 0.0137"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0139 - mean_absolute_error: 0.0139 - val_loss: 0.0185 - val_mean_absolute_error: 0.0185\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.0145 - mean_absolute_error: 0.0145"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 5ms/step - loss: 0.0145 - mean_absolute_error: 0.0145 - val_loss: 0.0186 - val_mean_absolute_error: 0.0186\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "MAX_EPOCHS = 10\n",
    "lstm_model = modelobasico( x_train_norm,y_train_norm,x_val_norm,y_val_norm,batch_size,MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_model.predict(x_test_norm)\n",
    "\n",
    "\n",
    "predicciones_LSTM = y_pred.reshape(-1, 1)\n",
    "\n",
    "# desnormalizamos\n",
    "pred_LSTM_denorm = denormalize_y_pred(predicciones_LSTM, loaded_params[salida])\n",
    "y_t = y_tested\n",
    "pred_LSTM_denorm = pred_LSTM_denorm.ravel()\n",
    "pred_LSTM_denorm = pd.DataFrame({salida: pred_LSTM_denorm})\n",
    "\n",
    "# y_datos_test_dn_lstm\n",
    "\n",
    "y_t = np.array(y_t).squeeze(axis=1)\n",
    "print(predicciones_LSTM.shape, y_t.shape)\n",
    "pred_LSTM_denorm = np.array(pred_LSTM_denorm)\n",
    "mse_LSTM = mean_squared_error(y_t, pred_LSTM_denorm)\n",
    "\n",
    "correlacion = np.corrcoef(pred_LSTM_denorm.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LSTM = correlacion ** 2\n",
    "\n",
    "ns_LSTM = hydroeval.nse(y_t.reshape(-1),pred_LSTM_denorm.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_LSTM_denorm.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LSTM = np.std(diff_modelo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6305db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LSTM')\n",
    "print(f'NS test: {ns_LSTM}')\n",
    "print(f'MSE test: {mse_LSTM}')\n",
    "print(f'R2 test: {r_cuadrado_LSTM}')\n",
    "print(f'std test: {std_LSTM}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482291c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_LSTM_denorm , label='LSTM prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372210d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLR = LinearRegression()\n",
    "\n",
    "modeloLR.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247663b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_LR = modeloLR.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_LR = denormalize_y_pred(y_pred_LR, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_LR = mean_squared_error(y_t, pred_denorm_LR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_LR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_LR = hydroeval.nse(y_t.reshape(-1),pred_denorm_LR.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_LR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LR = np.std(diff_modelo_test)\n",
    "print('LR')\n",
    "print(f'NS test: {ns_LR}')\n",
    "print(f'MSE test: {mse_LR}')\n",
    "print(f'R2 test: {r_cuadrado_LR}')\n",
    "print(f'std test: {std_LR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_LR , label='LR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c052d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSVR = SVR()\n",
    "modeloSVR.fit(x_train_modelos_norm,y_train_norm)\n",
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_SVR = modeloSVR.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_SVR = denormalize_y_pred(y_pred_SVR, loaded_params[salida])\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_SVR = mean_squared_error(y_t, pred_denorm_SVR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_SVR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_SVR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_SVR = hydroeval.nse(y_t.reshape(-1),pred_denorm_SVR.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_SVR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_SVR = np.std(diff_modelo_test)\n",
    "print('SVR')\n",
    "print(f'NS test: {ns_SVR}')\n",
    "print(f'MSE test: {mse_SVR}')\n",
    "print(f'R2 test: {r_cuadrado_SVR}')\n",
    "print(f'std test: {std_SVR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e658a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_SVR , label='SVR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloRF = RandomForestRegressor()\n",
    "\n",
    "modeloRF.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_RF = modeloRF.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_RF = denormalize_y_pred(y_pred_RF, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_RF = mean_squared_error(y_t, pred_denorm_RF)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_RF.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_RF = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_RF = hydroeval.nse(y_t.reshape(-1),pred_denorm_RF.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_RF.reshape(-1)-y_t.reshape(-1))     \n",
    "std_RF = np.std(diff_modelo_test)\n",
    "print('RF')\n",
    "print(f'NS test: {ns_RF}')\n",
    "print(f'MSE test: {mse_RF}')\n",
    "print(f'R2 test: {r_cuadrado_RF}')\n",
    "print(f'std test: {std_RF}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038fd90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_RF , label='RF prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a664450",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloXGB = XGBRegressor()\n",
    "\n",
    "modeloXGB.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df0969",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_XGB = modeloXGB.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_XGB = denormalize_y_pred(y_pred_XGB, loaded_params[salida])\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_XGB = mean_squared_error(y_t, pred_denorm_XGB)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_XGB.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_XGB = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_XGB = hydroeval.nse(y_t.reshape(-1),pred_denorm_XGB.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_XGB.reshape(-1)-y_t.reshape(-1))     \n",
    "std_XGB = np.std(diff_modelo_test)\n",
    "print('XGB')\n",
    "print(f'NS test: {ns_XGB}')\n",
    "print(f'MSE test: {mse_XGB}')\n",
    "print(f'R2 test: {r_cuadrado_XGB}')\n",
    "print(f'std test: {std_XGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_XGB , label='XGB prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(feature_importance_scores, dataset, ultimo_envio):\n",
    "    # Get the feature names from the dataset\n",
    "    feature_names = dataset.columns.values\n",
    "\n",
    "    # Sort the feature importance scores in descending order\n",
    "    sorted_idx = feature_importance_scores.argsort()[::-1]\n",
    "    sorted_scores = feature_importance_scores[sorted_idx]\n",
    "\n",
    "    # Ajustar el tamaño de la gráfica\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    # Aumentar el tamaño de la fuente de los textos\n",
    "    plt.xticks(range(len(sorted_scores)), feature_names[sorted_idx], rotation=270, fontsize=30) # Ajustar el tamaño de la fuente\n",
    "    plt.yticks(fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "\n",
    "    # Reducir el ancho de las barras\n",
    "    plt.bar(range(len(sorted_scores)), sorted_scores, width=0.2)  # Ajustar el ancho de las barras\n",
    "\n",
    "    plt.title(\"Sensitivity Analysis\", fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "    plt.xlabel(\"Variables\", fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "    plt.ylabel(\"RMSE Variation\", fontsize=30)  # Ajustar el tamaño de la fuente\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    plt.savefig(buffer, format='png')\n",
    "    buffer.seek(0)\n",
    "    presente = time.time()\n",
    "    if presente - ultimo_envio < 3:\n",
    "        time.sleep(3 - (presente-ultimo_envio))\n",
    "    bot.send_photo(idchatconbot, buffer)\n",
    "    ultimo_envio = time.time()\n",
    "    buffer.close()\n",
    "    plt.show()\n",
    "    return ultimo_envio\n",
    "\n",
    "def analisis_sensib_final(modelo,x_data,y_data,norm, salida, ultimo_envio=ultimo_envio):\n",
    "# parte de análisis de sensibilidad con el modelo\n",
    "    # evaluate utiliza la función de pérdida definida en el modelo lstm para calcular el loss entre\n",
    "    # las predicciones y la salida real\n",
    "    if len(x_data.shape) == 3:\n",
    "        num_features = x_data.shape[2]\n",
    "    else:\n",
    "        num_features = x_data.shape[1]\n",
    "    try:\n",
    "        baseline_score = modelo.evaluate(x_data, y_data, verbose=0)[0]\n",
    "        baseline = denormalize_y_pred(baseline_score, loaded_params[salida])\n",
    "        \n",
    "    except AttributeError:\n",
    "        baseline_score = np.mean(cross_val_score(modelo,x_data,y_data,cv=3))\n",
    "        baseline = denormalize_y_pred(baseline_score, loaded_params[salida])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Initialize an array to store the importance scores\n",
    "    feature_importance_scores = np.zeros(num_features)\n",
    "\n",
    "    # Loop through each feature\n",
    "    for i in range(num_features):       \n",
    "        # Evaluate devuelve el loss entre y_pred e y_true\n",
    "        X_removed = x_data.copy()\n",
    "        if len(X_removed.shape) == 3:\n",
    "            X_removed[:,:,i] = 0\n",
    "        else:\n",
    "            X_removed.iloc[:,i] = 0\n",
    "        try:\n",
    "\n",
    "            sc2 = modelo.evaluate(X_removed, y_data, verbose=0)[0]\n",
    "        except AttributeError:\n",
    "\n",
    "            sc2 = np.mean(cross_val_score(modelo,X_removed,y_data,cv=3))\n",
    "        \n",
    "        score = denormalize_y_pred(sc2,loaded_params[salida])\n",
    "\n",
    "        #print(f'loss desnormalizado una variable = 0: {score} loss desnormalizado todas variables: {baseline} , \\nloss normalizado una variable = 0: {sc2} loss normalizado todas variables: {baseline_score} \\n\\n')\n",
    "        # Calculate the decrease in performance\n",
    "        feature_importance_scores[i] = ((score - baseline) / baseline) * 100\n",
    "\n",
    "        # Reset the weights of the model\n",
    "        if len(X_removed.shape) == 3:\n",
    "            modelo.reset_states()\n",
    "    \n",
    "    \n",
    "    mejores_5 = c.rank_five(feature_importance_scores)\n",
    "    nombres = x_train_modelos.columns.tolist()\n",
    "    for j, item in enumerate(mejores_5):\n",
    "        mensaje_rank = f\"Ranking {j+1} feature {nombres[item]} {feature_importance_scores[item]:.3f}%\\n\"\n",
    "        print(mensaje_rank)\n",
    "        #bot.send_message(idchatconbot, mensaje_rank)\n",
    "    #ploteado = g.Graficas(ultimo_envio=ultimo_envio)\n",
    "    ultimo_envio = plot_feature_importance(feature_importance_scores=feature_importance_scores[mejores_5], dataset= x_train_modelos,ultimo_envio=ultimo_envio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838affc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analisis_sensib_final(modeloXGB,x_train_modelos_norm,y_train_norm,loaded_params,salida,ultimo_envio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8156e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a1c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeloANN = Al.crear_red_ann((x_train_modelos_norm,y_train_norm),num_capas_ocultas=1,num_neuronas=24,funcion_activacion=\"sigmoid\",regularizador=0.0001,optimizador=0.001,num_salidas=1,fn_perdida=tf.keras.losses.MeanSquaredError(),metrica=tf.keras.metrics.MeanSquaredError())\n",
    "\n",
    "\n",
    "modeloANN.fit(x_train_modelos_norm,y_train_norm, epochs = MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_ANN = modeloANN.predict(x_test_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_ANN = denormalize_y_pred(y_pred_ANN, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_ANN = mean_squared_error(y_t, pred_denorm_ANN)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_ANN.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_ANN = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_ANN = hydroeval.nse(y_t.reshape(-1),pred_denorm_ANN.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_ANN.reshape(-1)-y_t.reshape(-1))     \n",
    "std_ANN = np.std(diff_modelo_test)\n",
    "print('ANN')\n",
    "print(f'NS test: {ns_ANN}')\n",
    "print(f'MSE test: {mse_ANN}')\n",
    "print(f'R2 test: {r_cuadrado_ANN}')\n",
    "print(f'std test: {std_ANN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f739fd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_ANN , label='ANN prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37cbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_modelos[salida].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# para naive es simple, cojo el valor de entrada de Qe como predicción\n",
    "\n",
    "y_pred_Naive = x_test_modelos_norm[salida].values\n",
    "# desnormalizamos\n",
    "pred_denorm_Naive = denormalize_y_pred(y_pred_Naive, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_tested\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_Naive = mean_squared_error(y_t, pred_denorm_Naive)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_Naive.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_Naive = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_Naive = hydroeval.nse(y_t.reshape(-1),pred_denorm_Naive.reshape(-1))\n",
    "\n",
    "diff_modelo_test = np.abs(pred_denorm_Naive.reshape(-1)-y_t.reshape(-1))     \n",
    "std_Naive = np.std(diff_modelo_test)\n",
    "print('Naive')\n",
    "print(f'NS test: {ns_Naive}')\n",
    "print(f'MSE test: {mse_Naive}')\n",
    "print(f'R2 test: {r_cuadrado_Naive}')\n",
    "print(f'std test: {std_Naive}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c56c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_Naive , label='Naive prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in test with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64df42d",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3953b9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "MAX_EPOCHS = 500\n",
    "lstm_model = modelobasico( x_train_norm,y_train_norm,x_val_norm,y_val_norm,batch_size,MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20afde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_model.predict(x_train_norm)\n",
    "\n",
    "\n",
    "predicciones_LSTM = y_pred.reshape(-1, 1)\n",
    "\n",
    "# desnormalizamos\n",
    "pred_LSTM_denorm = denormalize_y_pred(predicciones_LSTM, loaded_params[salida])\n",
    "y_t = y_train\n",
    "pred_LSTM_denorm = pred_LSTM_denorm.ravel()\n",
    "pred_LSTM_denorm = pd.DataFrame({salida: pred_LSTM_denorm})\n",
    "\n",
    "# y_datos_test_dn_lstm\n",
    "\n",
    "y_t = np.array(y_t).squeeze(axis=1)\n",
    "print(predicciones_LSTM.shape, y_t.shape)\n",
    "pred_LSTM_denorm = np.array(pred_LSTM_denorm)\n",
    "mse_LSTM = mean_squared_error(y_t, pred_LSTM_denorm)\n",
    "\n",
    "correlacion = np.corrcoef(pred_LSTM_denorm.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LSTM = correlacion ** 2\n",
    "\n",
    "ns_LSTM = hydroeval.nse(y_t.reshape(-1),pred_LSTM_denorm.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_LSTM_denorm.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LSTM = np.std(diff_modelo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LSTM')\n",
    "print(f'NS train: {ns_LSTM}')\n",
    "print(f'MSE train: {mse_LSTM}')\n",
    "print(f'R2 train: {r_cuadrado_LSTM}')\n",
    "print(f'std train: {std_LSTM}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eacc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_LSTM_denorm , label='LSTM prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bfef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloLR = LinearRegression()\n",
    "\n",
    "modeloLR.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_LR = modeloLR.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_LR = denormalize_y_pred(y_pred_LR, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_LR = mean_squared_error(y_t, pred_denorm_LR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_LR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_LR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_LR = hydroeval.nse(y_t.reshape(-1),pred_denorm_LR.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_LR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_LR = np.std(diff_modelo_train)\n",
    "print('LR')\n",
    "print(f'NS train: {ns_LR}')\n",
    "print(f'MSE train: {mse_LR}')\n",
    "print(f'R2 train: {r_cuadrado_LR}')\n",
    "print(f'std train: {std_LR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7662458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_LR , label='LR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloSVR = SVR()\n",
    "modeloSVR.fit(x_train_modelos_norm,y_train_norm)\n",
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_SVR = modeloSVR.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_SVR = denormalize_y_pred(y_pred_SVR, loaded_params[salida])\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_SVR = mean_squared_error(y_t, pred_denorm_SVR)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_SVR.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_SVR = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_SVR = hydroeval.nse(y_t.reshape(-1),pred_denorm_SVR.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_SVR.reshape(-1)-y_t.reshape(-1))     \n",
    "std_SVR = np.std(diff_modelo_train)\n",
    "print('SVR')\n",
    "print(f'NS train: {ns_SVR}')\n",
    "print(f'MSE train: {mse_SVR}')\n",
    "print(f'R2 train: {r_cuadrado_SVR}')\n",
    "print(f'std train: {std_SVR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40843f58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_SVR , label='SVR prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloRF = RandomForestRegressor()\n",
    "\n",
    "modeloRF.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_RF = modeloRF.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_RF = denormalize_y_pred(y_pred_RF, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_RF = mean_squared_error(y_t, pred_denorm_RF)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_RF.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_RF = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_RF = hydroeval.nse(y_t.reshape(-1),pred_denorm_RF.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_RF.reshape(-1)-y_t.reshape(-1))     \n",
    "std_RF = np.std(diff_modelo_train)\n",
    "print('RF')\n",
    "print(f'NS train: {ns_RF}')\n",
    "print(f'MSE train: {mse_RF}')\n",
    "print(f'R2 train: {r_cuadrado_RF}')\n",
    "print(f'std train: {std_RF}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_de_caracteristicas = x_train_modelos_norm.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "arbol_seleccionado = modeloRF.estimators_[0]\n",
    "\n",
    "# Crear un archivo DOT que representa la estructura del árbol\n",
    "archivo_dot = export_graphviz(arbol_seleccionado, out_file=None, feature_names=nombre_de_caracteristicas, rounded=True, precision=2)\n",
    "\n",
    "# Visualizar el árbol con Graphviz\n",
    "grafo = graphviz.Source(archivo_dot)\n",
    "grafo.render(\"arbol_visualizado\", format=\"png\", cleanup=True)\n",
    "\n",
    "# Abre el archivo generado para ver el árbol visualizado\n",
    "grafo.view(\"arbol_visualizado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eab13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_RF , label='RF prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e905f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeloXGB = XGBRegressor()\n",
    "\n",
    "modeloXGB.fit(x_train_modelos_norm,y_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51116a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_XGB = modeloXGB.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_XGB = denormalize_y_pred(y_pred_XGB, loaded_params[salida])\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_XGB = mean_squared_error(y_t, pred_denorm_XGB)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_XGB.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_XGB = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_XGB = hydroeval.nse(y_t.reshape(-1),pred_denorm_XGB.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_XGB.reshape(-1)-y_t.reshape(-1))     \n",
    "std_XGB = np.std(diff_modelo_train)\n",
    "print('XGB')\n",
    "print(f'NS train: {ns_XGB}')\n",
    "print(f'MSE train: {mse_XGB}')\n",
    "print(f'R2 train: {r_cuadrado_XGB}')\n",
    "print(f'std train: {std_XGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_XGB , label='XGB prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff6ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modeloANN = c.crear_red_ann((x_train_modelos_norm,y_train_norm),num_capas_ocultas=1,num_neuronas=24,funcion_activacion=\"sigmoid\",regularizador=0.0001,optimizador=0.001,num_salidas=1,fn_perdida=tf.keras.losses.MeanSquaredError(),metrica=tf.keras.metrics.MeanSquaredError())\n",
    "\n",
    "\n",
    "modeloANN.fit(x_train_modelos_norm,y_train_norm, epochs = MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# como las salidas de lstm comienzan a partir de la ventanta temporal + salida, para poder comparar el resto tengo que quitar las primeras entradas\n",
    "\n",
    "y_pred_ANN = modeloANN.predict(x_train_modelos_norm)\n",
    "# desnormalizamos\n",
    "pred_denorm_ANN = denormalize_y_pred(y_pred_ANN, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_ANN = mean_squared_error(y_t, pred_denorm_ANN)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_ANN.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_ANN = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_ANN = hydroeval.nse(y_t.reshape(-1),pred_denorm_ANN.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_ANN.reshape(-1)-y_t.reshape(-1))     \n",
    "std_ANN = np.std(diff_modelo_train)\n",
    "print('ANN')\n",
    "print(f'NS train: {ns_ANN}')\n",
    "print(f'MSE train: {mse_ANN}')\n",
    "print(f'R2 train: {r_cuadrado_ANN}')\n",
    "print(f'std train: {std_ANN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc889e6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_ANN , label='ANN prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b103fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_modelos[salida].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PREDICCIONES #####\n",
    "\n",
    "# para naive es simple, cojo el valor de entrada de Qe como predicción\n",
    "\n",
    "y_pred_Naive = x_train_modelos_norm[salida].values\n",
    "# desnormalizamos\n",
    "pred_denorm_Naive = denormalize_y_pred(y_pred_Naive, loaded_params[salida])\n",
    "\n",
    "\n",
    "###### ETIQUETAS REALES #####\n",
    "\n",
    "y_t = y_train\n",
    "# es un array de (355,1,1) le cambio el formato para que tenga el mismo que las predicciones (355,) y así poder calcular las métricas\n",
    "\n",
    "\n",
    "\n",
    "##### MSE ####\n",
    "\n",
    "mse_Naive = mean_squared_error(y_t, pred_denorm_Naive)\n",
    "\n",
    "\n",
    "##### correlacion #####\n",
    "correlacion = np.corrcoef(pred_denorm_Naive.reshape(-1),y_t.reshape(-1),rowvar=False)[0][1]\n",
    "r_cuadrado_Naive = correlacion ** 2\n",
    "\n",
    "##### NS #####\n",
    "\n",
    "ns_Naive = hydroeval.nse(y_t.reshape(-1),pred_denorm_Naive.reshape(-1))\n",
    "\n",
    "diff_modelo_train = np.abs(pred_denorm_Naive.reshape(-1)-y_t.reshape(-1))     \n",
    "std_Naive = np.std(diff_modelo_train)\n",
    "print('Naive')\n",
    "print(f'NS train: {ns_Naive}')\n",
    "print(f'MSE train: {mse_Naive}')\n",
    "print(f'R2 train: {r_cuadrado_Naive}')\n",
    "print(f'std train: {std_Naive}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362c53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un array de índices para el eje x (puede ser simplemente un rango numérico)\n",
    "x_indices = np.arange(len(y_t))\n",
    "\n",
    "\n",
    "# Crear la figura y los ejes\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Graficar los valores reales (y_test)\n",
    "ax.plot(x_indices, y_t, label='Real Value',  color='red',linestyle='-')\n",
    "\n",
    "# Graficar las predicciones del modelo LSTM (y_pred_lstm)\n",
    "ax.plot(x_indices, pred_denorm_Naive , label='Naive prediction', color='green', linestyle='--')\n",
    "\n",
    "# Etiquetas de los ejes y título\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Outflow value')\n",
    "ax.set_title(f'Output Flow in train with {gap} day gap and {input_width} day info comparison')\n",
    "\n",
    "# Leyenda\n",
    "ax.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
